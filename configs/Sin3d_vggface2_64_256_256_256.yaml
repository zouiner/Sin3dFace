model:
  target: models.SinSR.unet.UNetModelSwin
  ckpt_path: /users/ps1510/scratch/Programs/SinSR/logs/model/SinSR_train_64_256/model_30000.pth # /users/ps1510/scratch/Programs/Sin3dFace/data/weights/SinSR_v2.pth
  teacher_ckpt_path: data/weights/resshift_realsrx4_s15_v1.pth
  params:
    image_size: 64
    in_channels: 6
    model_channels: 160
    out_channels: 3
    cond_lq: True
    attention_resolutions: [64,32,16,8]
    dropout: 0
    channel_mult: [1, 2, 2, 4]
    num_res_blocks: [2, 2, 2, 2]
    conv_resample: True
    dims: 2
    use_fp16: False
    num_head_channels: 32
    use_scale_shift_norm: True
    resblock_updown: False
    swin_depth: 2
    swin_embed_dim: 192
    window_size: 8
    mlp_ratio: 4

diffusion:
  target: models.SinSR.script_util.create_gaussian_diffusion
  params:
    sf: 4 # scale factor 
    schedule_name: exponential
    schedule_kwargs:
      power: 0.3
    etas_end: 0.99
    steps: 15
    min_noise_level: 0.04
    kappa: 2.0
    weighted_mse: False
    predict_type: xstart
    timestep_respacing: ~
    scale_factor: 1.0
    normalize_input: True
    latent_flag: True

autoencoder:
  target: ldm.models.autoencoder.VQModelTorch
  ckpt_path: data/weights/autoencoder_vq_f4.pth
  use_fp16: True
  params:
    embed_dim: 3
    n_embed: 8192
    ddconfig:
      double_z: False
      z_channels: 3
      resolution: 256
      in_channels: 3
      out_ch: 3
      ch: 128
      ch_mult:
      - 1
      - 2
      - 4
      num_res_blocks: 2
      attn_resolutions: []
      dropout: 0.0
      padding_mode: zeros

degradation:
  sf: 4
  # the first degradation process
  resize_prob: [0.2, 0.7, 0.1]  # up, down, keep
  resize_range: [0.15, 1.5]
  gaussian_noise_prob: 0.5
  noise_range: [1, 30]
  poisson_scale_range: [0.05, 3.0]
  gray_noise_prob: 0.4
  jpeg_range: [30, 95]

  # the second degradation process
  second_order_prob: 0.5
  second_blur_prob: 0.8
  resize_prob2: [0.3, 0.4, 0.3]  # up, down, keep
  resize_range2: [0.3, 1.2]
  gaussian_noise_prob2: 0.5
  noise_range2: [1, 25]
  poisson_scale_range2: [0.05, 2.5]
  gray_noise_prob2: 0.4
  jpeg_range2: [30, 95]

  gt_size: 256 
  resize_back: False
  use_sharp: False

data:
  train:
    type: 3dSin
    params:
      dir_path: /users/ps1510/scratch/Programs/3d-super-resolution-Face-reconstruction/contents/LYHM_64_256/hr_256
      dir_path_extra: ~
      im_exts: ['JPEG', 'png', 'jpg']
      io_backend:
        type: disk
      blur_kernel_size: 21
      kernel_list: ['iso', 'aniso', 'generalized_iso', 'generalized_aniso', 'plateau_iso', 'plateau_aniso']
      kernel_prob: [0.45, 0.25, 0.12, 0.03, 0.12, 0.03]
      sinc_prob: 0.1
      blur_sigma: [0.2, 3.0]
      betag_range: [0.5, 4.0]
      betap_range: [1, 2.0]

      blur_kernel_size2: 15
      kernel_list2: ['iso', 'aniso', 'generalized_iso', 'generalized_aniso', 'plateau_iso', 'plateau_aniso']
      kernel_prob2: [0.45, 0.25, 0.12, 0.03, 0.12, 0.03]
      sinc_prob2: 0.1
      blur_sigma2: [0.2, 1.5]
      betag_range2: [0.5, 4.0]
      betap_range2: [1, 2.0]

      final_sinc_prob: 0.8

      gt_size: 256
      crop_pad_size: 300
      use_hflip: True
      use_rot: False
      rescale_gt: True
  val:
    type: folder
    params:
      dir_path: testdata/RealSet128/
      dir_path_extra: ~
      transform_type: default
      transform_kwargs:
          mean: 0.5
          std: 0.5
      im_exts: png
      length: ~
      recursive: False

train:
  learn_xT: True
  finetune_use_gt: 1.
  # xT_cov_loss: 0.1

  lr: 5e-5
  batch: [24, 2]   # batchsize for training and validation // val size will be K*batch[1] 
  use_fp16: False
  microbatch: 6 # 16 # should be divided by K(2) in MICA # total_b = int(micro_b/K)*num_acc*GPUs
  seed: 123456
  global_seeding: False
  prefetch_factor:  4
  num_workers: 1
  ema_rate: 0.999
  iterations: 500000
  milestones: [5000, 500000]
  weight_decay: 0
  save_freq: 1000
  # val_freq:  10000
  # log_freq: [1000, 5000, 1] #[training loss, training images, val images]
  val_freq:  2000
  log_freq: [1000, 500, 10] #[training loss, training images, val images]
  save_images: True  # save the images of tensorboard logging
  use_ema_val: True
  train_size: 0.95 # val size = train_size - 0.2


MICA:
  target: models.mica.mica.MICA
  ckpt_path: ""

  model:
    name: 'mica'
    testing: False
    topology_path: "data/FLAME2020/head_template.obj"
    flame_model_path: "data/FLAME2020/generic_model.pkl"
    flame_lmk_embedding_path: "data/FLAME2020/landmark_embedding.npy"
    n_shape: 300
    n_pose: 6
    n_exp: 50
    layers: 8
    hidden_layers_size: 256
    mapping_layers: 3
    use_pretrained: False
    arcface_pretrained_model: "data/pretrained/backbone.pth"

  # Dataset options
  dataset:
    root: 'datasets/arcface'
    training_data: ['LYHM']
    eval_data: ['LYHM']
    batch_size: 8
    num_workers: 4
    K: 2

  # Mask weights
  mask_weights:
    face: 150.0
    nose: 50.0
    lips: 50.0
    forehead: 50.0
    lr_eye_region: 50.0
    eye_region: 50.0
    whole: 1.0
    ears: 0.01
    eyes: 0.01

  running_average: 7

  # Training options
  train:
    lr: 1e-5
    arcface_lr: 1e-5
    weight_decay: 2e-4
    use_mask: True
    reset_optimizer: False
    max_steps: 1600000
    max_epochs: 50
    log_steps: 50
    val_steps: 300
    vis_steps: 1200
    val_save_img: 1200
    checkpoint_steps: 1000
    checkpoint_epochs_steps: 10000
    log_dir: 'logs'
    vis_dir: 'train_images'
    val_vis_dir: 'val_images'
    write_summary: True

# export OMP_NUM_THREADS=1
# python3 -m debugpy --listen 0.0.0.0:5678 --wait-for-client -m torch.distributed.run --nproc_per_node=3 main_distill.py --cfg_path configs/Sin3d_vggface2_16_64_256_64.yaml --save_dir logs/Sin3d_vggface2_16_64_256_64
# python3 -m torch.distributed.run --nproc_per_node=3 main_distill.py --cfg_path configs/Sin3d_vggface2_16_64_256_64.yaml --save_dir logs/Sin3d_vggface2_16_64_256_64